{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def list2dict(ls):\n",
    "    dic = dict()\n",
    "    for term in ls:\n",
    "        if term not in dic:\n",
    "            dic[term] = 1\n",
    "        else:\n",
    "            dic[term] += 1\n",
    "    return dic\n",
    "\n",
    "def data_formating(raw_df):\n",
    "    df = raw_df\n",
    "    df['Phrase'] = df.Phrase.apply(lambda s: s.lower())\n",
    "    #df = raw_df.assign(PhraseSplit=raw_df.Phrase.apply(lambda s: list2dict(str.split(s, \" \"))))\n",
    "    df = raw_df.assign(PhraseSplit=raw_df.Phrase.apply(lambda s: str.split(str(s), \" \")))\n",
    "    df = df.assign(WordTotal=df.PhraseSplit.apply(lambda l: len(l)), Length=data.Phrase.apply(len))\n",
    "    idx_empty = df[df.Phrase==\" \"].index[0]\n",
    "    df = df.drop(idx_empty)\n",
    "    return df\n",
    "\n",
    "def rvwhitespace(s):\n",
    "    if s=='' or s==' ' :\n",
    "        return ''\n",
    "    if s[0]==' ':\n",
    "        i=1\n",
    "    else:\n",
    "        i=0\n",
    "    if s[-1]==' ':\n",
    "        return s[i:-1]\n",
    "    else:\n",
    "        return s[i:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train.tsv\", sep=\"\\t\")\n",
    "data = data_formating(data).reset_index().drop('index', 1).sort_values('WordTotal').reset_index().drop(['index','SentenceId'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NV = max(data[data.WordTotal==1].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = 40\n",
    "P = tf.Variable(tf.random_normal([d, NV]))\n",
    "Ws = tf.Variable(tf.random_normal([5, d]))\n",
    "W  = tf.Variable(tf.random_normal([d, 2*d]))\n",
    "\n",
    "def selectfromSoftmax(p):\n",
    "    return (tf.nn.softmax(tf.transpose(tf.matmul(Ws, p))), tf.argmax(tf.nn.softmax(tf.transpose(tf.matmul(Ws, p))), dimension=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dic     = {data.Phrase.ix[i]: i for i in data.index}\n",
    "dic_sen = {data.Phrase.ix[i]: data.Sentiment.ix[i] for i in data.index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(123000, 156059)\n",
      "(124000, 156059)\n",
      "(125000, 156059)\n",
      "(126000, 156059)\n",
      "(127000, 156059)\n",
      "(128000, 156059)\n",
      "(129000, 156059)\n",
      "(130000, 156059)\n",
      "(131000, 156059)\n",
      "(132000, 156059)\n",
      "(133000, 156059)\n",
      "(134000, 156059)\n",
      "(135000, 156059)\n",
      "(136000, 156059)\n",
      "(137000, 156059)\n",
      "(138000, 156059)\n",
      "(139000, 156059)\n",
      "(140000, 156059)\n",
      "(141000, 156059)\n",
      "(142000, 156059)\n",
      "(143000, 156059)\n",
      "(144000, 156059)\n",
      "(145000, 156059)\n",
      "(146000, 156059)\n",
      "(147000, 156059)\n",
      "(148000, 156059)\n",
      "(149000, 156059)\n",
      "(150000, 156059)\n",
      "(151000, 156059)\n",
      "(152000, 156059)\n",
      "(153000, 156059)\n",
      "(154000, 156059)\n",
      "(155000, 156059)\n",
      "(156000, 156059)\n"
     ]
    }
   ],
   "source": [
    "# construct one 2x|Phrases| matrix and one |Phrases|-length vector, matrix stores the first index of the phrase's child and amount of children\n",
    "# the vector stores children's index\n",
    "\n",
    "def isslicein(sl, s):\n",
    "    n=len(sl)\n",
    "    return ((sl+\" \" in s) & (s[:n]==sl)) | ((\" \"+sl in s) & (s[-n::1]==sl)) | (\" \"+sl+\" \" in s) \n",
    "    # middle\n",
    "    #mi = \" \"+sl+\" \" in s\n",
    "    # left\n",
    "    #le = (sl+\" \" in s) & (s[0]==sl[0])\n",
    "    # right\n",
    "    #ri = (\" \"+sl in s) & (s[-1]==sl[-1])\n",
    "\n",
    "data = data.sort_values(['WordTotal', 'Length'], ascending=False)\n",
    "\n",
    "def phrase2indexes(s, df):\n",
    "    slst = str.split(s)\n",
    "    numword = len(slst)\n",
    "\n",
    "    if numword == 1:\n",
    "        print(df)\n",
    "        return [df[df.Phrase==s].index[0]]\n",
    "    \n",
    "    if numword == 2:\n",
    "        child = str.split(s)\n",
    "        return [df[df.Phrase==child[0]].index[0], df[df.Phrase==child[1]].index[0]]\n",
    "    #child = data[(data.WordTotal <= numword) & (data.Phrase.apply(lambda st: isslicein(st, s)))]\n",
    "    child = df[(df.WordTotal < numword)]\n",
    "    child = child[(child.Phrase.apply(lambda st: isslicein(st, s)))]\n",
    "    bigChildPhrase = child.Phrase.iloc[0]\n",
    "    bigChildIndex  = child.index[0]\n",
    "    otherchilds = str.split(s, bigChildPhrase)\n",
    "\n",
    "    ro0 = rvwhitespace(otherchilds[0])\n",
    "    ro1 = rvwhitespace(otherchilds[1])\n",
    "    if otherchilds[0]=='':\n",
    "        if ro1 in child.Phrase.get_values():\n",
    "            return [bigChildIndex, child[child.Phrase==ro1].index[0]]\n",
    "        else:\n",
    "            lst = [bigChildIndex]\n",
    "            lst = lst + phrase2indexes(ro1, child)\n",
    "            return lst\n",
    "    elif otherchilds[-1]=='':\n",
    "        if ro0 in child.Phrase.get_values():\n",
    "            return [child[child.Phrase==ro0].index[0], bigChildIndex]\n",
    "        else:\n",
    "            lst = phrase2indexes(ro0, child)\n",
    "            lst.append(bigChildIndex)\n",
    "            return lst\n",
    "    else:\n",
    "        if ro0 in child.Phrase.get_values():\n",
    "            prevIdxes = [child[child.Phrase==ro0].index[0]]\n",
    "        else:\n",
    "            prevIdxes    = phrase2indexes(ro0, child)\n",
    "        \n",
    "        if ro1 in child.Phrase.get_values():\n",
    "            laterIdxes = [child[child.Phrase==ro1].index[0]]\n",
    "        else:\n",
    "            laterIdxes    = phrase2indexes(ro1, child)\n",
    "        return prevIdxes + [bigChildIndex] + laterIdxes\n",
    "    \n",
    "#index_rec = np.zeros((2, data.shape[0]), dtype=np.int32)\n",
    "#entry_rec = []\n",
    "\n",
    "#entry_flag = 0\n",
    "#length = data.shape[0]\n",
    "while (i<length):\n",
    "    if i%1000==0:\n",
    "        print(i, length)\n",
    "    indexes = phrase2indexes( data.ix[i].Phrase, data)\n",
    "    index_rec[0, i] = entry_flag\n",
    "    index_rec[1, i] = len(indexes)\n",
    "    entry_rec = entry_rec+indexes\n",
    "    entry_flag = entry_flag + len(indexes)\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Length</th>\n",
       "      <th>WordTotal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>156057</th>\n",
       "      <td>87836</td>\n",
       "      <td>there are n't too many films that can be as si...</td>\n",
       "      <td>4</td>\n",
       "      <td>259</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156056</th>\n",
       "      <td>75358</td>\n",
       "      <td>build some robots , haul 'em to the theatre wi...</td>\n",
       "      <td>0</td>\n",
       "      <td>251</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156058</th>\n",
       "      <td>35599</td>\n",
       "      <td>it cuts to the core of what it actually means ...</td>\n",
       "      <td>4</td>\n",
       "      <td>218</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156051</th>\n",
       "      <td>105156</td>\n",
       "      <td>... spiced with humor -lrb- ' i speak fluent f...</td>\n",
       "      <td>3</td>\n",
       "      <td>283</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156055</th>\n",
       "      <td>18579</td>\n",
       "      <td>if you are curious to see the darker side of w...</td>\n",
       "      <td>1</td>\n",
       "      <td>258</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PhraseId                                             Phrase  \\\n",
       "156057     87836  there are n't too many films that can be as si...   \n",
       "156056     75358  build some robots , haul 'em to the theatre wi...   \n",
       "156058     35599  it cuts to the core of what it actually means ...   \n",
       "156051    105156  ... spiced with humor -lrb- ' i speak fluent f...   \n",
       "156055     18579  if you are curious to see the darker side of w...   \n",
       "\n",
       "        Sentiment  Length  WordTotal  \n",
       "156057          4     259         52  \n",
       "156056          0     251         52  \n",
       "156058          4     218         52  \n",
       "156051          3     283         51  \n",
       "156055          1     258         51  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def phrase2wordindexes(s, df):\n",
    "    slst = str.split(s)\n",
    "    numword = len(slst)\n",
    "\n",
    "    if numword == 1:\n",
    "        print(df)\n",
    "        return [df[df.Phrase==s].index[0]]\n",
    "    \n",
    "    if numword == 2:\n",
    "        child = str.split(s)\n",
    "        return [df[df.Phrase==child[0]].index[0], df[df.Phrase==child[1]].index[0]]\n",
    "    #child = data[(data.WordTotal <= numword) & (data.Phrase.apply(lambda st: isslicein(st, s)))]\n",
    "    child = df[(df.WordTotal < numword)]\n",
    "    child = child[(child.Phrase.apply(lambda st: isslicein(st, s)))]\n",
    "    bigChildPhrase = child.Phrase.iloc[0]\n",
    "    bigChildIndex  = child.index[0]\n",
    "    otherchilds = str.split(s, bigChildPhrase)\n",
    "\n",
    "    ro0 = rvwhitespace(otherchilds[0])\n",
    "    ro1 = rvwhitespace(otherchilds[1])\n",
    "    if otherchilds[0]=='':\n",
    "        if ro1 in child.Phrase.get_values():\n",
    "            return [bigChildIndex, child[child.Phrase==ro1].index[0]]\n",
    "        else:\n",
    "            lst = [bigChildIndex]\n",
    "            lst = lst + phrase2indexes(ro1, child)\n",
    "            return lst\n",
    "    elif otherchilds[-1]=='':\n",
    "        if ro0 in child.Phrase.get_values():\n",
    "            return [child[child.Phrase==ro0].index[0], bigChildIndex]\n",
    "        else:\n",
    "            lst = phrase2indexes(ro0, child)\n",
    "            lst.append(bigChildIndex)\n",
    "            return lst\n",
    "    else:\n",
    "        if ro0 in child.Phrase.get_values():\n",
    "            prevIdxes = [child[child.Phrase==ro0].index[0]]\n",
    "        else:\n",
    "            prevIdxes    = phrase2indexes(ro0, child)\n",
    "        \n",
    "        if ro1 in child.Phrase.get_values():\n",
    "            laterIdxes = [child[child.Phrase==ro1].index[0]]\n",
    "        else:\n",
    "            laterIdxes    = phrase2indexes(ro1, child)\n",
    "        return prevIdxes + [bigChildIndex] + laterIdxes\n",
    "def Prob(s):\n",
    "    indexes = phrase2wordindexes(s, data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#np.savetxt('index_rec.txt', index_rec, fmt='%d')\n",
    "#np.savetxt('entry_rec.txt', entry_rec, fmt='%d')\n",
    "j = np.loadtxt('index_rec.txt', dtype=np.int32)\n",
    "l = np.loadtxt('entry_rec.txt', dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15612, 13899]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 30000\n",
    "tar = index_rec[:,idx]\n",
    "idxes = entry_rec[tar[0]:tar[0]+tar[1]]\n",
    "\n",
    "lst=[]\n",
    "for idx in idxes:\n",
    "    if index_rec[1,idx]==1:\n",
    "        lst = lst + [idx]\n",
    "lst\n",
    "\n",
    "def "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def child(idx):\n",
    "    s = data.Phrase.ix[idx]\n",
    "    slst = str.split(s)\n",
    "    numword = len(slst)\n",
    "    if numword==1:\n",
    "        return [idx]\n",
    "    child = data[(data.WordTotal < numword) & (data.Phrase.apply(lambda st: isslicein(st, s)))].sort_values(['WordTotal', 'Length'], ascending=False)\n",
    "    bigChildPhrase = child.Phrase.iloc[0]\n",
    "    bigChildIndex  = child.index[0]\n",
    "    otherchild = str.split(s, bigChildPhrase)\n",
    "    \n",
    "    if otherchild[0]=='':\n",
    "        bigChildP   = prob(bigChildPhrase)\n",
    "        otherchildP = prob(rvwhitespace(otherchild[1]))\n",
    "        p = inference(bigChildP, otherchildP)\n",
    "    elif otherchild[-1]=='':\n",
    "        bigChildP   = prob(bigChildPhrase)\n",
    "        otherchildP = prob(rvwhitespace(otherchild[0]))\n",
    "        p = inference(otherchildP, bigChildP)\n",
    "    else:\n",
    "        bigChildP   = prob(bigChildPhrase)\n",
    "        prevP       = prob(rvwhitespace(otherchild[0]))\n",
    "        laterP      = prob(rvwhitespace(otherchild[-1]))\n",
    "        p = inference( prevP, inference(bigChildP, laterP) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "child(50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dic     = {data.Phrase.ix[i]: i for i in data.index}\n",
    "dic_sen = {data.Phrase.ix[i]: data.Sentiment.ix[i] for i in data.index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def isslicein(sl, s):\n",
    "    # middle\n",
    "    mi = \" \"+sl+\" \" in s\n",
    "    # left\n",
    "    le = (sl+\" \" in s) & (s[0]==sl[0])\n",
    "    # right\n",
    "    ri = (\" \"+sl in s) & (s[-1]==sl[-1])\n",
    "    return mi | le | ri\n",
    "\n",
    "def inference(firstP, secondP):\n",
    "    return tf.nn.tanh( tf.matmul( W, tf.concat(0, [firstP, secondP]) ) )\n",
    "\n",
    "def prob(s):\n",
    "    slst = str.split(s)\n",
    "    numword = len(slst)\n",
    "    if numword==1:\n",
    "        return tf.transpose([P[:,dic[s]]])\n",
    "    \n",
    "    child = data[(data.WordTotal < numword) & (data.Phrase.apply(lambda st: isslicein(st, s)))].sort_values(['WordTotal', 'Length'], ascending=False)\n",
    "    bigChildPhrase = child.Phrase.iloc[0]\n",
    "    otherchild = str.split(s, bigChildPhrase)\n",
    "    \n",
    "    if otherchild[0]=='':\n",
    "        bigChildP   = prob(bigChildPhrase)\n",
    "        otherchildP = prob(rvwhitespace(otherchild[1]))\n",
    "        p = inference(bigChildP, otherchildP)\n",
    "    elif otherchild[-1]=='':\n",
    "        bigChildP   = prob(bigChildPhrase)\n",
    "        otherchildP = prob(rvwhitespace(otherchild[0]))\n",
    "        p = inference(otherchildP, bigChildP)\n",
    "    else:\n",
    "        bigChildP   = prob(bigChildPhrase)\n",
    "        prevP       = prob(rvwhitespace(otherchild[0]))\n",
    "        laterP      = prob(rvwhitespace(otherchild[-1]))\n",
    "        p = inference( prevP, inference(bigChildP, laterP) )\n",
    "    #if s in dic.keys():\n",
    "        #p_op.append(P[:, dic[s]].assign(p[:,0]))\n",
    "    return p\n",
    "\n",
    "def cost(s):\n",
    "    s_vec, k = selectfromSoftmax( prob(s) )\n",
    "    k = dic_sen[s]\n",
    "    return - tf.log( s_vec[0,k] )\n",
    "\n",
    "xs = data.Phrase.sample(100).get_values()\n",
    "\n",
    "loss = tf.reduce_sum( [cost(s) for s in xs] )\n",
    "\n",
    "def string_length(t):\n",
    "  return tf.py_func(lambda p: [len(x) for x in p], [t], [tf.int64])[0]\n",
    "\n",
    "def Loss(xs):\n",
    "    \n",
    "    for i in range(tf.shape(xs)[0]):\n",
    "        s = xs[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 測試區塊\n",
    "s = \"trenchant ,\"\n",
    "slst = str.split(s)\n",
    "numword = len(slst)\n",
    "child = data[(data.WordTotal < numword) & (data.Phrase.apply(lambda st: isslicein(st, s)))].sort_values('WordTotal', ascending=False)\n",
    "bigChildPhrase = child.Phrase.iloc[0]\n",
    "otherchild = str.split(s, bigChildPhrase)\n",
    "\n",
    "if otherchild[0]=='':\n",
    "    bigChildP   = prob(bigChildPhrase)\n",
    "    otherchildP = prob(rvwhitespace(otherchild[1]))\n",
    "    p = tf.nn.tanh( tf.matmul( W, tf.concat(0, [bigChildP, otherchildP]) ) )\n",
    "elif otherchild[-1]=='':\n",
    "    bigChildP   = prob(bigChildPhrase)\n",
    "    otherchildP = prob(rvwhitespace(otherchild[0]))\n",
    "    p = tf.nn.tanh( tf.matmul( W, tf.concat(0, [otherchildP, bigChildP]) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#xs = data.Phrase.sample(20).get_values()\n",
    "#loss = tf.reduce_sum( [cost(s) for s in xs] )\n",
    "train = tf.train.GradientDescentOptimizer(0.01).minimize(loss)\n",
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "for loop in range(1000):\n",
    "    sess.run(train)\n",
    "    print(sess.run( loss ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.close()\n",
    "t = tf.train.GradientDescentOptimizer(0.0001)\n",
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.assign(lens=data.Phrase.apply(len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index_rec = np.loadtxt('index_rec.txt', dtype=np.int32)\n",
    "entry_rec = np.loadtxt('entry_rec.txt', dtype=np.int32)\n",
    "\n",
    "NV = max(data[data.WordTotal==1].index)\n",
    "d = 40\n",
    "P = tf.Variable(tf.random_normal([NV, d]))\n",
    "Ws = tf.Variable(tf.random_normal([5, d]))\n",
    "W  = tf.Variable(tf.random_normal([d, 2*d]))\n",
    "\n",
    "index_tf = tf.constant(index_rec, dtype=tf.int32)\n",
    "entry_tf = tf.constant(entry_rec, dtype=tf.int32)\n",
    "\n",
    "def selectfromSoftmax(p):\n",
    "    return tf.nn.softmax(tf.transpose(tf.matmul(Ws, p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.setrecursionlimit(10000)\n",
    "\n",
    "def leaf_prob(idx):\n",
    "    return tf.gather(P, idx)\n",
    "def node_prob(idx):\n",
    "    subidx = entry_tf[index_tf[0,idx]:index_tf[0,idx]+index_tf[1,idx]]\n",
    "    #revidx = subidx[-1::-1]\n",
    "    #p = prob(revidx[0])\n",
    "    p = prob(subidx[0])\n",
    "    for i in range(1,index_tf[1,idx]):\n",
    "        p = tf.nn.tanh( tf.matmul( W, tf.concat(0, [p, prob(subidx[i])]) ) )\n",
    "    #return p * (1-less_para) + p0\n",
    "    return p\n",
    "\n",
    "def prob(idx):\n",
    "    less_para = tf.cast(tf.less(idx, tf.constant(NV, tf.int32)), tf.float32)\n",
    "    p0 = less_para * tf.gather(P, idx)\n",
    "    #if idx.eval(session=sess)<NV:\n",
    "    #   return tf.gather(P, idx)\n",
    "    subidx = entry_tf[index_tf[0,idx]:index_tf[0,idx]+index_tf[1,idx]]\n",
    "    #revidx = subidx[-1::-1]\n",
    "    #p = prob(revidx[0])\n",
    "    #p = prob(subidx[0])\n",
    "    #for i in range(1,index_tf[1,idx].eval(session=sess)):\n",
    "    #   p = tf.nn.tanh( tf.matmul( W, tf.transpose(tf.concat(0, [p, prob(subidx[i])]) ) ) )\n",
    "    p = tf.nn.tanh( tf.matmul( W, tf.transpose([tf.concat(0, [prob(subidx[0]), prob(subidx[1])])]) ) )\n",
    "    return p * (1-less_para) + p0\n",
    "    \n",
    "def single_cost(idx, sentiment):\n",
    "    softmax = selectfromSoftmax( prob(idx) )\n",
    "    return - tf.log( softmax[0, sentiment] )\n",
    "\n",
    "idx_tf = tf.placeholder(tf.int32, shape=None)\n",
    "sen_tf = tf.placeholder(tf.int32, shape=None)\n",
    "\n",
    "loss = single_cost(idx_tf, sen_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "In[1] is not a matrix\n\t [[Node: MatMul_3 = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Variable_2/read, transpose_1)]]\n\nCaused by op u'MatMul_3', defined at:\n  File \"/usr/local/Cellar/python/2.7.12_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/local/Cellar/python/2.7.12_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python2.7/site-packages/traitlets/config/application.py\", line 589, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 403, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python2.7/site-packages/tornado/ioloop.py\", line 883, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 260, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 212, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 370, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 175, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2723, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2831, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-15-03dea7aecd9e>\", line 7, in <module>\n    sess.run(tf.shape(prob(tf.constant(41362))))\n  File \"<ipython-input-14-0809f1e186d1>\", line 26, in prob\n    p = tf.nn.tanh( tf.matmul( W, tf.transpose(tf.concat(0, [p, prob(subidx[i])]) ) ) )\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py\", line 1398, in matmul\n    name=name)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1348, in _mat_mul\n    transpose_b=transpose_b, name=name)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 749, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2380, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1298, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): In[1] is not a matrix\n\t [[Node: MatMul_3 = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Variable_2/read, transpose_1)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-03dea7aecd9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#sess.run(prob(tf.constant(20)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m41362\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 717\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    718\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 915\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    916\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 965\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: In[1] is not a matrix\n\t [[Node: MatMul_3 = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Variable_2/read, transpose_1)]]\n\nCaused by op u'MatMul_3', defined at:\n  File \"/usr/local/Cellar/python/2.7.12_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/local/Cellar/python/2.7.12_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python2.7/site-packages/traitlets/config/application.py\", line 589, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 403, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 162, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python2.7/site-packages/tornado/ioloop.py\", line 883, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 260, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 212, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 370, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 175, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2723, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2831, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-15-03dea7aecd9e>\", line 7, in <module>\n    sess.run(tf.shape(prob(tf.constant(41362))))\n  File \"<ipython-input-14-0809f1e186d1>\", line 26, in prob\n    p = tf.nn.tanh( tf.matmul( W, tf.transpose(tf.concat(0, [p, prob(subidx[i])]) ) ) )\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py\", line 1398, in matmul\n    name=name)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1348, in _mat_mul\n    transpose_b=transpose_b, name=name)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 749, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2380, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1298, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): In[1] is not a matrix\n\t [[Node: MatMul_3 = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Variable_2/read, transpose_1)]]\n"
     ]
    }
   ],
   "source": [
    "#train = tf.train.GradientDescentOptimizer(0.01).minimize(loss)\n",
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(init)\n",
    "#sess.run(prob(tf.constant(20)))\n",
    "sess.run(tf.shape(prob(tf.constant(41362))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>PhraseSplit</th>\n",
       "      <th>Length</th>\n",
       "      <th>WordTotal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41362</th>\n",
       "      <td>3</td>\n",
       "      <td>a series</td>\n",
       "      <td>2</td>\n",
       "      <td>[a, series]</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PhraseId    Phrase  Sentiment  PhraseSplit  Length  WordTotal\n",
       "41362         3  a series          2  [a, series]       8          2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.Phrase=='a series']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-4eb681f84119>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'loss' is not defined"
     ]
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
